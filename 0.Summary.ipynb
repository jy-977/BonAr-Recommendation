{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0.Summary.ipynb","provenance":[],"collapsed_sections":["2jau55DbaqEe","Jp4LwCQ9n2dF","bL6iNgcMnx42","NfPo90DTnk6z","OiZaWPAZa28W","9TP_VLYErKYq","4EtBhjxhsGky"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"l9qEUR2tXBpW"},"source":["# Grocery Store Suggestions System\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KSwkYfb1XPBw"},"source":["\n","In the daily life, we use to forget something and realize after arriving at home. To solve this problem and increase the client satisfaction, our team suggest a recommendation system for online and off-line store in this project. We aim to help our customer shop in a convenient environment by suggesting the related producted based on the actual data presendted by bonÀrea. "]},{"cell_type":"markdown","metadata":{"id":"DBPPFS7iYQWG"},"source":["## 1. Business use case"]},{"cell_type":"markdown","metadata":{"id":"rzMcZH6gZ2OR"},"source":["### Goals"]},{"cell_type":"markdown","metadata":{"id":"_en6zG32Yf6C"},"source":["In this project, \n","The objective of this project is to do an analysis of the sales history of the stores and purchase data to predict products that are highly relevant to the purchasing products. \n","Based on this prediction, we present a recommendation solution considering purchasing circumstance like holiday, event, or time. \n","\n","The different applications of this analysis can be suggestions on the website at the moment of the payment, on the waiting lines, printed on the receipt (as a reminder for the next time).\n","\n","These solutions can be helpful to provide customer-oriented experience to our clients. We are able to expect the increase of the potencial customer and long-term sales performance. \n"]},{"cell_type":"markdown","metadata":{"id":"fUZNGwd5ZFBU"},"source":["### Possible Obstacles"]},{"cell_type":"markdown","metadata":{"id":"JpfE-GlQZ-Vv"},"source":["- The computation with big datasets could be  higher an do it for each store (we  have more than 500) could take a long time.\n","- The results need to be used in the low performance computers as POS (Point of Sale) systems.\n","- Determine in advance the price of the computation.\n","- In which way is it possible to combine dataset related to the purchasing habits of different socio-economic groups with those we have. It could add some complexity to our analysis.\n","- Short time to do the project.\n"]},{"cell_type":"markdown","metadata":{"id":"v-9E5izcacnm"},"source":["## 2. Technical requirements"]},{"cell_type":"markdown","metadata":{"id":"2jau55DbaqEe"},"source":["### Data sources\n","\n","The company of Grocery stores has a headquarter where all information of stores are collected to its databases. From these databases with ETLs the data is exported to the csv files  that are needed for this project.  (These part is done in company and is out of range of this document).\n","\n","The files are 3: \n","- The **families** \n","- The **products**\n","- The **breakdown of receipts**\n","\n","The lines could be related with families by products table.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Jp4LwCQ9n2dF"},"source":["#### Families:\n","\n","The families are the form to group products by similar types. Each scale of group the similarity are higher. This families are based from AECOC offers (https://www.aecoc.es/guias/clasificacion-estandarizada-de-producto/).\n","\n","AECOC is an Spanish association of producers and distributors that is also associated with a global GS1 organization. One of their targets is offer a several standards and family codes is one of them.\n","\n","The standard offers till 5 levels of classification but this company nowadays only works with 3 levels.\n","\n","Sample of some lines:\n","```csv\n","FAMILIA ;DESCRIPCIO.SECTOR ; DESCRIPCIO.SECCIO  ;DESC.FAMILIA ;;;;\n","01*01*01 ;Alimentacion y Bebidas  ;ALIMENTACIÓN SECA ;Aceites ;;;;\n","01*01*02 ;Alimentacion y Bebidas  ;ALIMENTACIÓN SECA ;Cafés y sucedáneos ;;;;\n","...\n","01*02*01 ;Alimentacion y Bebidas  ;CONSERVAS ;Conservas de pescado y marisco ;;;;\n","01*02*02 ;Alimentacion y Bebidas  ;CONSERVAS ;Conservas vegetales ;;;;\n","...\n","01*03*01 ;Alimentacion y Bebidas  ;Làcteos y derivados ;Leche ;;;;\n","01*03*02 ;Alimentacion y Bebidas  ;Làcteos y derivados ;Leches no liquidas ;;;;\n","...\n","01*04*01 ;Alimentacion y Bebidas  ;BEBIDAS ;Aguas ;;;;\n","01*04*02 ;Alimentacion y Bebidas  ;BEBIDAS ;Bebidas refrescantes ;;;;\n","...\n","```"]},{"cell_type":"markdown","metadata":{"id":"bL6iNgcMnx42"},"source":["#### Products:\n","This file comes with a properly headers on csv file. This file relate each product with its family. The information of family is joined in a unique string and splited by sector,section and family.\n","\n","Sample of some lines:\n","```csv\n","ARTICLE;DESCRIPCIO;SECTOR;SECCIO;FAMILIA;DESC\n","10002;LIMPIACRISTALES BONA;3;1;6;03*01*06\n","10003;LIMPIACRISTALES BONA;3;1;6;03*01*06\n","10004;FREGASUELOS CAG 1 L;3;1;6;03*01*06\n","10006;VAJILLAS CONCENTRADO;3;1;4;03*01*04\n","10007;VAJILLAS VERDE BONAC;3;1;4;03*01*04\n","...\n","```"]},{"cell_type":"markdown","metadata":{"id":"NfPo90DTnk6z"},"source":["#### Breakdown of receipt:\n","\n","This file contains each product that are sold. The invoice_id group each line that is sold to unique customer. Each file contains all lines sold by one checkout in a year. So, This could have easily more that one milion of lines.\n","\n","This file comes without headers. But we obtained the meaning of each column.\n","\n","1. Invoice id. This code inform us that all lines with same id are sold to the same customer. Also has a correlated number and where is done (store number and checkout number). The format are:\n"," - 2 digit: year\n"," - 2 digit: company department\n"," - dash '-'\n"," - T + 4 digits : Store number\n"," - C + 2 digits : Checkout number\n"," - dash '-'\n"," - Number of invoice.\n","2. Product id.\n","3. Units. This column is multiplied by one million.\n","4. Amount. This is total amount that the customer pay, not the product price. This is multiplied by a hundred.\n","5. Day. Day in Julian format that Julian period starts on January 1th, 1968. Also with modulus of 7 we can know the week day (0 = Sunday).\n","7. Time. Is the number of seconds from midnight.\n","\n","Sample of some lines:\n","```csv\n","2027-T0101C01-100089;3055;1000000;24;01;19343;35707\n","2027-T0101C01-100089;3055;1000000;24;01;19343;35707\n","2027-T0101C01-100089;6989;1000000;0;01;19343;35707\n","2027-T0101C01-100188;8939;1000000;226;01;19343;44143\n","2027-T0101C01-100188;8939;1000000;228;01;19343;44143\n","...\n","```"]},{"cell_type":"markdown","metadata":{"id":"OiZaWPAZa28W"},"source":["### How to work with the data\n","\n","The Data will be explored using techniques of Artificial intelligence. A-priori style algorithms or using some kind of Neural Networks. \n","\n","Some kinds of classification could do that the results are different. For example according to the time, if the day is holiday or the time of year. The total amount or the number of products. etc. \n","\n","The brand of product should not be important so other kind of job is work with the families at distinct levels. On the data exploration, we observed that some families have tens of products, so we decided to work with products.\n","\n","The computation is convenient to be with some architecture that allows to parallelize the jobs. The number of stores and sells are big and it's desired that the time to get results was short. So, use utilities as spark could be a good ally.\n","\n","The place to work at the beginning is *Google Colab®* because they offer us a shared platform to work collaboratively and computers with GPU or TPU deliver something to carry out the work. When the project evolves it is possible to hire more or more large services."]},{"cell_type":"markdown","metadata":{"id":"W_S60moyo3Pw"},"source":["This project has just started in *Google Colab®* and it has started with open and explore data from csv files."]},{"cell_type":"markdown","metadata":{"id":"rq4_bABwpepF"},"source":["As *Google Collab®* doen't has Spark installed by default, next block prepare the environment to can work with Spark. Also as this platform is efimer the data is managed with a mounted volume to *Google Drive®*. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"877neqeyd-JW","executionInfo":{"status":"ok","timestamp":1637858553232,"user_tz":-60,"elapsed":231888,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"aebd9233-239c-4b2b-902b-053cfe56657e"},"source":["try:\n","  # Only it runs in google collab\n","  from google.colab import drive # if this package don't exist we aren't con google colab\n","  import os\n","  # Install spark and its requirements\n","  !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","  !wget -nc -q https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n","  !tar xf spark-3.2.0-bin-hadoop3.2.tgz\n","  !pip install -q pyspark\n","  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","  os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\"\n","  drive.mount('/content/drive')\n","  base_path = '/content/drive/MyDrive/Master/Project Big Data/Project Big Data/' # Google Drive\n","except:\n","  # It runs in local \n","  base_path = ''\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 281.3 MB 41 kB/s \n","\u001b[K     |████████████████████████████████| 198 kB 69.1 MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"kxUqAHLfqOog"},"source":["Importing libraries to work with Spark and initializate a SparkSession."]},{"cell_type":"code","metadata":{"id":"XMf1r0Vl9Pa1"},"source":["# Import Spark libs\n","from pyspark.sql import SparkSession\n","from IPython.display import display, HTML\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","from pyspark.sql.functions import col\n","\n","\n","# Initiate SparkSession\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark SQL basic example\") \\\n","    .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n","    .getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qhb3Zp91qeKL"},"source":["The path of files. This uses a base path in order to be able to work this Jupyter notebook wherever (at moment in colab and local)."]},{"cell_type":"code","metadata":{"id":"KnHzjwyXVxGz"},"source":["# File Path\n","file_products = base_path + 'data/ARTICLES.csv'\n","file_families = base_path + 'data/AECOC.csv'\n","file_sells = base_path + 'data/s20.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TP_VLYErKYq"},"source":["#### Products file"]},{"cell_type":"code","metadata":{"id":"jEGnGUYwcb4D","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1637858566767,"user_tz":-60,"elapsed":8373,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"875f2e58-8f42-466a-f7d5-98e95e6ed815"},"source":["# CSV options\n","infer_schema = \"false\"\n","first_row_is_header = \"true\"\n","delimiter = \";\"\n","\n","df_product = spark.read.format('csv') \\\n","  .option(\"charset\", \"ISO-8859-1\") \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_products)\n","df_product.limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ARTICLE</th>\n","      <th>DESCRIPCIO</th>\n","      <th>SECTOR</th>\n","      <th>SECCIO</th>\n","      <th>FAMILIA</th>\n","      <th>DESC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>LIMPIACRISTALES CON</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>03*01*06</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>LIMPIACRISTALES RECA</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>03*01*06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>LIMPIACRISTALES BONA</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>03*01*06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>LIMPIACRISTALES BONA</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>03*01*06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>FREGASUELOS CAG 1 L</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>03*01*06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  ARTICLE            DESCRIPCIO SECTOR SECCIO FAMILIA      DESC\n","0   10000   LIMPIACRISTALES CON      3      1       6  03*01*06\n","1   10001  LIMPIACRISTALES RECA      3      1       6  03*01*06\n","2   10002  LIMPIACRISTALES BONA      3      1       6  03*01*06\n","3   10003  LIMPIACRISTALES BONA      3      1       6  03*01*06\n","4   10004   FREGASUELOS CAG 1 L      3      1       6  03*01*06"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"JKXBRL8SrpwN"},"source":["It make a projection of this file with selected columns and normalized its name."]},{"cell_type":"code","metadata":{"id":"NsuYrMXvX1hZ","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1637858568377,"user_tz":-60,"elapsed":1615,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"fc6914c2-0d35-403c-cccd-51f1d2d580ee"},"source":["print (\"total products: \", df_product.count())\n","df_product.selectExpr('ARTICLE as product_id','DESC as family_id', 'DESCRIPCIO as product_desc' ).limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total products:  72200\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>family_id</th>\n","      <th>product_desc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>03*01*06</td>\n","      <td>LIMPIACRISTALES CON</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>03*01*06</td>\n","      <td>LIMPIACRISTALES RECA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>03*01*06</td>\n","      <td>LIMPIACRISTALES BONA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>03*01*06</td>\n","      <td>LIMPIACRISTALES BONA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>03*01*06</td>\n","      <td>FREGASUELOS CAG 1 L</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  product_id family_id          product_desc\n","0      10000  03*01*06   LIMPIACRISTALES CON\n","1      10001  03*01*06  LIMPIACRISTALES RECA\n","2      10002  03*01*06  LIMPIACRISTALES BONA\n","3      10003  03*01*06  LIMPIACRISTALES BONA\n","4      10004  03*01*06   FREGASUELOS CAG 1 L"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"4EtBhjxhsGky"},"source":["#### Families file"]},{"cell_type":"code","metadata":{"id":"RIC6sh-NVreL","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1637858569770,"user_tz":-60,"elapsed":1398,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"eacb5dd8-b02f-4889-e0f5-1a3bf9cdf9f6"},"source":["# CSV options\n","infer_schema = \"false\"\n","first_row_is_header = \"true\"\n","delimiter = \";\"\n","\n","df_families = spark.read.format('csv') \\\n","  .option(\"charset\", \"ISO-8859-1\") \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_families)\n","\n","df_families.limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FAMILIA</th>\n","      <th>DESCRIPCIO.SECTOR</th>\n","      <th>DESCRIPCIO.SECCIO</th>\n","      <th>DESC.FAMILIA</th>\n","      <th>_c4</th>\n","      <th>_c5</th>\n","      <th>_c6</th>\n","      <th>_c7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00*00*00</td>\n","      <td>Desconocido</td>\n","      <td></td>\n","      <td>Desconeguda</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01*01*01</td>\n","      <td>Alimentacion y Bebidas</td>\n","      <td>ALIMENTACIÓN SECA</td>\n","      <td>Aceites</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01*01*02</td>\n","      <td>Alimentacion y Bebidas</td>\n","      <td>ALIMENTACIÓN SECA</td>\n","      <td>Cafés y sucedáneos</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01*01*03</td>\n","      <td>Alimentacion y Bebidas</td>\n","      <td>ALIMENTACIÓN SECA</td>\n","      <td>Infusiones</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01*01*04</td>\n","      <td>Alimentacion y Bebidas</td>\n","      <td>ALIMENTACIÓN SECA</td>\n","      <td>Chocolates</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    FAMILIA         DESCRIPCIO.SECTOR   DESCRIPCIO.SECCIO    ...   _c5   _c6   _c7\n","0  00*00*00               Desconocido                        ...  None  None  None\n","1  01*01*01   Alimentacion y Bebidas     ALIMENTACIÓN SECA   ...  None  None  None\n","2  01*01*02   Alimentacion y Bebidas     ALIMENTACIÓN SECA   ...  None  None  None\n","3  01*01*03   Alimentacion y Bebidas     ALIMENTACIÓN SECA   ...  None  None  None\n","4  01*01*04   Alimentacion y Bebidas     ALIMENTACIÓN SECA   ...  None  None  None\n","\n","[5 rows x 8 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"E_guEnkgsWls","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1637858570042,"user_tz":-60,"elapsed":275,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"c4a7c1f0-181a-4280-8cae-a687532d4dc3"},"source":["schema = StructType([\n","    StructField(\"family_id\", StringType(), True),\n","    StructField(\"sector_desc\", StringType(), True),\n","    StructField(\"section_desc\", StringType(), True),\n","    StructField(\"family_desc\", StringType(), True),\n","    StructField(\"not_use1\", StringType(), True),\n","    StructField(\"not_use2\", StringType(), True),\n","    StructField(\"not_use3\", StringType(), True),\n","    StructField(\"not_use4\", StringType(), True)\n","    ])\n","\n","df_families = spark.read.format('csv') \\\n","  .schema(schema) \\\n","  .option(\"charset\", \"ISO-8859-1\") \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_families)\n","\n","\n","print (\"total families: \", df_families.count())\n","\n","df_families.select(col('family_id'), col('family_desc') ).limit(5).toPandas()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total families:  816\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>family_id</th>\n","      <th>family_desc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00*00*00</td>\n","      <td>Desconeguda</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01*01*01</td>\n","      <td>Aceites</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01*01*02</td>\n","      <td>Cafés y sucedáneos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01*01*03</td>\n","      <td>Infusiones</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01*01*04</td>\n","      <td>Chocolates</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   family_id          family_desc\n","0  00*00*00          Desconeguda \n","1  01*01*01              Aceites \n","2  01*01*02   Cafés y sucedáneos \n","3  01*01*03           Infusiones \n","4  01*01*04           Chocolates "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"j1iB1QkiWChg","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1637858571320,"user_tz":-60,"elapsed":1281,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"8d250d42-5b1b-4c5e-97fe-869f8d9bf284"},"source":["# CSV options\n","infer_schema = \"false\"\n","first_row_is_header = \"false\"\n","delimiter = \";\"\n","\n","schema = StructType([\n","    StructField(\"invoice_id\", StringType(), True),\n","    StructField(\"product_id\", IntegerType(), True),\n","    StructField(\"quantity\", IntegerType(), True),\n","    StructField(\"amount\", IntegerType(), True),\n","    StructField(\"checkout\", IntegerType(), True),\n","    StructField(\"date\", IntegerType(), True),\n","    StructField(\"hour\", IntegerType(), True),])\n","\n","df_sells = spark.read.format('csv') \\\n","  .schema(schema) \\\n","  .option(\"charset\", \"ISO-8859-1\") \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_sells)\n","\n","df_sells.limit(5).toPandas()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>invoice_id</th>\n","      <th>product_id</th>\n","      <th>quantity</th>\n","      <th>amount</th>\n","      <th>checkout</th>\n","      <th>date</th>\n","      <th>hour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>5379</td>\n","      <td>1000000</td>\n","      <td>171</td>\n","      <td>1</td>\n","      <td>19282</td>\n","      <td>64396</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>5379</td>\n","      <td>1000000</td>\n","      <td>160</td>\n","      <td>1</td>\n","      <td>19282</td>\n","      <td>64396</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>3482</td>\n","      <td>1000000</td>\n","      <td>63</td>\n","      <td>1</td>\n","      <td>19282</td>\n","      <td>64396</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>3059</td>\n","      <td>1000000</td>\n","      <td>45</td>\n","      <td>1</td>\n","      <td>19282</td>\n","      <td>64396</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>3059</td>\n","      <td>1000000</td>\n","      <td>45</td>\n","      <td>1</td>\n","      <td>19282</td>\n","      <td>64396</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             invoice_id  product_id  quantity  amount  checkout   date   hour\n","0  2027-T0105C01-100089        5379   1000000     171         1  19282  64396\n","1  2027-T0105C01-100089        5379   1000000     160         1  19282  64396\n","2  2027-T0105C01-100089        3482   1000000      63         1  19282  64396\n","3  2027-T0105C01-100089        3059   1000000      45         1  19282  64396\n","4  2027-T0105C01-100089        3059   1000000      45         1  19282  64396"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"8JlxmL3NVaW7","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1637858575763,"user_tz":-60,"elapsed":4447,"user":{"displayName":"Sergi Trujillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNO4stFClv2w6fKSH3WS_GzsLaYVX-RKd-xGg0Mw=s64","userId":"02136148069551221503"}},"outputId":"9eb2938e-1165-45f1-c1ca-ed9c89270a86"},"source":["from datetime import datetime,timedelta\n","\n","print(\"total sells: \", df_sells.count())\n","\n","StartDate = \"12/31/1967\"\n","Date = datetime.strptime(StartDate, \"%m/%d/%Y\")\n","\n","df_sells = df_sells.rdd \\\n","  .map(lambda x: (x[0],x[1],x[2]/1000000,x[3]/100,x[4],Date.replace(hour=0, minute=0, second=0, microsecond =0)+timedelta(days=x[5], seconds=x[6]))) \\\n","  .toDF(['invoice_id','product_id', 'quantity','amount','checkout','datetime'])\n","\n","df_sells.limit(5).toPandas()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total sells:  1263376\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>invoice_id</th>\n","      <th>product_id</th>\n","      <th>quantity</th>\n","      <th>amount</th>\n","      <th>checkout</th>\n","      <th>datetime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>5379</td>\n","      <td>1.0</td>\n","      <td>1.71</td>\n","      <td>1</td>\n","      <td>2020-10-15 17:53:16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>5379</td>\n","      <td>1.0</td>\n","      <td>1.60</td>\n","      <td>1</td>\n","      <td>2020-10-15 17:53:16</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>3482</td>\n","      <td>1.0</td>\n","      <td>0.63</td>\n","      <td>1</td>\n","      <td>2020-10-15 17:53:16</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>3059</td>\n","      <td>1.0</td>\n","      <td>0.45</td>\n","      <td>1</td>\n","      <td>2020-10-15 17:53:16</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2027-T0105C01-100089</td>\n","      <td>3059</td>\n","      <td>1.0</td>\n","      <td>0.45</td>\n","      <td>1</td>\n","      <td>2020-10-15 17:53:16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             invoice_id  product_id  ...  checkout            datetime\n","0  2027-T0105C01-100089        5379  ...         1 2020-10-15 17:53:16\n","1  2027-T0105C01-100089        5379  ...         1 2020-10-15 17:53:16\n","2  2027-T0105C01-100089        3482  ...         1 2020-10-15 17:53:16\n","3  2027-T0105C01-100089        3059  ...         1 2020-10-15 17:53:16\n","4  2027-T0105C01-100089        3059  ...         1 2020-10-15 17:53:16\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"lNevdgfREacq"},"source":["## 3. Steps to follow"]},{"cell_type":"markdown","metadata":{"id":"x7gzd-UXEgU5"},"source":["To put order and meaning to this project it need to be done following this steps: \n","\n","1.   **Data cleaning**: Review that the data obtained has no gabs and confim that prices and units are in confirmance ranks.\n","2.   **Data modeling**: Choose ML algorithm for suggestions. Making models for products and families.\n","3.   **Training and testing**: Define a training dataset and a Test dataset. Execute the process and test that if model generated complies.\n","4.   **Analyse the results**: Make some strategies to analyse if the results given are as expected and detect if some parameter affects negatively to results. Some kind of plot can be a helper to visualize the results.\n","\n"]},{"cell_type":"markdown","source":["# 4. Data Exploration\n","\n","https://colab.research.google.com/drive/14cBbxQoxdX_3kSPNl9m9djfAu3raOLfm?usp=sharing\n"],"metadata":{"id":"bSZLBlrKHsRn"}},{"cell_type":"markdown","source":["#5. Methodology"],"metadata":{"id":"YrvUdetzEMAy"}},{"cell_type":"markdown","source":["In our project, we chose to try different recommendation algorithms, so we can compare the results and the accuracy of each one. At the end, we will be able to choose the most suitable for us.\n","To compare the performance, we decided to use a benchmarck algorithm : it will recommend randomly a product among the top 10 best-selling products of the store (https://colab.research.google.com/drive/1eZv1LIOMXJC2oiDcBY-4iInMcGYUB2xl?usp=sharing)"],"metadata":{"id":"t-cz237OEc_9"}},{"cell_type":"markdown","source":["##Evaluation Strategy \n","*How will we evaluate the performance of our models and compare them?*\n","\n","\n","\n","*   Train the model with 80% of the data. We used the data of 2020 for one store.\n","*   With the test dataset : for the purchases with 3 products or more, delete the first product.\n","*   Run the model on these purchases (that are incomplete).\n","*   Compare the prediction.\n","*   Calculate the *precision* by dividing the number of good precisions by the size of the test dataset.\n","\n","In the future we will try to get the *coverage* metric, because it will allow us to check the percentage of the catalog that is recommended at least once. This is a good metric to see if the recommendation algorithm is balanced, and not recommmend the same products almost each time. \n","\n","The *recall* can be calculated when you recommend many products and you want to see the global accuracy of your recommended list. "],"metadata":{"id":"czpijN-2E5Is"}},{"cell_type":"markdown","source":["## The algorithms\n","\n","\n","\n","###Frequent Pattern Mining (FP-Growth)\n","\n","*   Based on user-item interaction matrix\n","*   The Item-based model (off-line) : we “ssume that users will mostly be interested by items similar to the one they have interacted with in the past”. Here, the similarity between two items is based on how many users had bought both in the past.\n","\n","\n","###Collaborative filtering (ALS)\n","\n","\n","*   Based on user-item interaction matrix\n","*   The matrix factorization approach can be seen as an extension of the item-based one, where we consider both similarity between the items and between the users.\n","*   The main drawback of matrix factorization is that you have to retrain from scratch your model each time there is a new user or a new user-item interaction to take it into account.\n","\n","\n","###Neural Network\n","\n","\n","*   With the neural networks model, we actually do on-line recommendations. By on-line, we mean that there is no need to precompute daily recommendations for all users — recommendations are computed on the fly, considering the latest items a user has interacted with.\n","*  we can’t capitalize on sequences of item interactions (we don’t know in which order the product has been put in the shopping cart) → it would have been a great advantage according to Decathlon’s team results.\n"],"metadata":{"id":"652BSmO3EniW"}},{"cell_type":"markdown","source":["#7. Obstacles\n","\n","\n","*   Choose algorithms and technologies.\n","*   Find the adequate performance metrics.\n","*   Dilemma between working with families or products.\n","*   Home office work that implies communication troubles.\n","*   Complexity of Neural Network model (lack of references).\n","*   We don’t know the profile of each buyer, neither the different carts they have bought.\n"],"metadata":{"id":"-lM0fWB9SJPz"}},{"cell_type":"markdown","source":["#8. Results\n","\n","Here are the precision we obtained for each model.\n","\n","*   Top 10 : 0.85%\n","*   FP-Growth : 2.44%\n","*   ALS : 3.21%\n","*   NN : --  (MSE : 0.2803522050380707) \n","\n","\n","\n"],"metadata":{"id":"gDw00ncQG45W"}},{"cell_type":"markdown","source":["#9. Conclusions\n","\n","\n","For one subject, a recommendation system, we had many options for the algorihms. To select the algorithms for recommendation system, we have researched about the history of the recommendation system. Moreover, we were able to know the difference of the Content based filtering and Collaborative Filtering method to implement the recommendation system.\n","So, we decided to implement both and compare them. We also tried to implement a Neural Network model.\n","\n","We started by implementing a methodology to be able to compare the results and calculated recommandations with a benchmarck algorithm.\n","\n","At the end, the best solution for us seems to be to use the Collaborative Filtering (ALS) method in this project, because it has better results than the Content based filtering (FP-Growth). Some other teams have used a model based on Neural Network with very good results (as the Decathlon team for example), but it is more difficult to build a model that suits in our case.\n","\n","To continue this project, we plan to refine our recommendation taking into account the purchase period. It was a goal that we could not accomplish due to lack of time.\n","\n","\n","\n"],"metadata":{"id":"nvOejQCUFIPi"}}]}